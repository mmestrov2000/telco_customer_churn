# ğŸ” Telco Customer Churn Prediction

This project aims to predict customer churn using the [Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn). It covers the full ML workflow: from data preprocessing and EDA to model training, evaluation, and optimization.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                  # YAML file for training configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Contains raw dataset (CSV)
â”‚   â””â”€â”€ processed/                   # Preprocessed data files
â”œâ”€â”€ models/
â”‚   â””â”€â”€ logistic_regression_v1/     # Saved model and config
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb                 # Exploratory Data Analysis notebook
â”œâ”€â”€ reports/                         # Placeholder for future reports/figures
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py                 # Data cleaning and encoding
â”‚   â”œâ”€â”€ evaluate.py                  # Model evaluation metrics
â”‚   â”œâ”€â”€ model.py                     # PyTorch logistic regression model
â”‚   â”œâ”€â”€ optimize.py                  # Hyperparameter tuning using Optuna
â”‚   â”œâ”€â”€ train.py                     # Model training pipeline
â”‚   â””â”€â”€ utils.py                     # Utility functions (if extended)
â”œâ”€â”€ main.py                          # Main training + evaluation script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š EDA (Exploratory Data Analysis)

EDA is conducted in [`notebooks/01_eda.ipynb`](notebooks/01_eda.ipynb). It includes:

- Feature distributions
- Churn vs non-churn behavior
- Correlation & trends
- Initial logistic regression analysis

---

## âš™ï¸ Configuration

All parameters (hyperparams, data paths, thresholds, device settings) are defined in `config/config.yaml`.

Example:
```yaml
model:
  lr: 0.0009
  weight_decay: 0.0015
  batch_size: 32
  max_epochs: 50
  threshold: 0.5751
  device: "cpu"
  seed: 42

data:
  path: "data/processed/telco_churn_processed.csv"
```

---

## ğŸ› ï¸ How to Run

### 1. ğŸ“¦ Preprocess Data
```bash
python src/data_prep.py
```

### 2. ğŸ§  Train & Evaluate Model
```bash
python main.py
```

### 3. ğŸ” Hyperparameter Tuning (Optional)
```bash
python -c "from src.optimize import run_optimization; run_optimization()"
```

---

## ğŸ“ˆ Evaluation Metrics

Implemented via `src/evaluate.py`:
- Accuracy
- Precision
- Recall
- F1 Score
- AUC (probability-based)
- Confusion Matrix

---

## ğŸ’¾ Model

Model is a simple logistic regression built with PyTorch (`src/model.py`), trained with early stopping based on validation AUC.

---

## ğŸ” Reproducibility

- Configurable via `config.yaml`
- Fixed random seed
- Trained with `train_test_split(stratify=True)`

---

## ğŸ“‹ Requirements

Install all dependencies with:
```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Notes

- Trained model is saved at: `models/logistic_regression_v1/logistic_regression_v1.pth`
- You can tweak config and rerun `main.py` for new experiments
- Add visual reports or exported plots to `/reports`
