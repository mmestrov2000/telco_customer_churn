# ğŸ” Telco Customer Churn Prediction

This project aims to predict customer churn using the [Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn). It covers the full ML workflow: from data preprocessing and EDA to model training, evaluation, and optimization.

---

## ğŸš€ Tech Stack

- **Python 3.7+**
- **PyTorch**: For model building and training
- **Optuna**: For hyperparameter tuning
- **FastAPI**: For serving the model as an API
- **Uvicorn**: ASGI server to run FastAPI
- **AWS EC2**: Model deployed on a Linux-based virtual machine
- **SCP / SSH**: To copy files and manage the remote server
- **Boto3**: (optional) for AWS interactions from Python

> âœ… Model was deployed on **Amazon Web Services (AWS)** using **EC2 instances** to explore, understand, and practice real-world ML deployment workflows.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/  
â”‚   â””â”€â”€ config.yaml                  # YAML file for training configuration  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                         # Contains raw dataset (CSV)  
â”‚   â””â”€â”€ processed/                   # Preprocessed data files  
â”œâ”€â”€ models/  
â”‚   â””â”€â”€ logistic_regression_v1/     # Saved model and config  
â”œâ”€â”€ notebooks/  
â”‚   â””â”€â”€ 01_eda.ipynb                 # Exploratory Data Analysis notebook  
â”œâ”€â”€ reports/                         # Placeholder for future reports/figures  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ data_prep.py                 # Data cleaning and encoding  
â”‚   â”œâ”€â”€ evaluate.py                  # Model evaluation metrics  
â”‚   â”œâ”€â”€ model.py                     # PyTorch logistic regression model  
â”‚   â”œâ”€â”€ optimize.py                  # Hyperparameter tuning using Optuna  
â”‚   â”œâ”€â”€ train.py                     # Model training pipeline  
â”‚   â””â”€â”€ utils.py                     # Utility functions (if extended)  
â”œâ”€â”€ main.py                          # Main training + evaluation script  
â”œâ”€â”€ test_api.py                      # Script to send a sample request to the deployed model  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md
```

---

## ğŸ“Š EDA (Exploratory Data Analysis)

EDA is conducted in [`notebooks/01_eda.ipynb`](notebooks/01_eda.ipynb). It includes:

- Feature distributions
- Churn vs non-churn behavior
- Correlation & trends
- Initial logistic regression analysis

---

## âš™ï¸ Configuration

All parameters (hyperparams, data paths, thresholds, device settings) are defined in `config/config.yaml`.

Example:
```yaml
model:
  lr: 0.0009
  weight_decay: 0.0015
  batch_size: 32
  max_epochs: 50
  threshold: 0.5751
  device: "cpu"
  seed: 42

data:
  path: "data/processed/telco_churn_processed.csv"
```

---

## ğŸ› ï¸ How to Run

### 1. ğŸ“¦ Preprocess Data
```bash
python src/data_prep.py
```

### 2. ğŸ§  Train & Evaluate Model
```bash
python main.py
```

### 3. ğŸ” Hyperparameter Tuning (Optional)
```bash
python -c "from src.optimize import run_optimization; run_optimization()"
```

---

## ğŸ“ˆ Evaluation Metrics

Implemented via `src/evaluate.py`:
- Accuracy
- Precision
- Recall
- F1 Score
- AUC (probability-based)
- Confusion Matrix

---

## ğŸ’¾ Model

Model is a simple logistic regression built with PyTorch (`src/model.py`), trained with early stopping based on validation AUC.

---

## ğŸ” Reproducibility

- Configurable via `config.yaml`
- Fixed random seed
- Trained with `train_test_split(stratify=True)`

---

## ğŸ“‹ Requirements

Install all dependencies with:
```bash
pip install -r requirements.txt
```
